{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a39d1dae",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "<!-- ```\n",
    "Architecture guidelines for stable Deep Convolutional GANs\n",
    "• Replace any pooling layers with strided convolutions (discriminator) and fractional-strided\n",
    "convolutions (generator).\n",
    "• Use BatchNorm in both the generator and the discriminator.\n",
    "• Remove fully connected hidden layers for deeper architectures.\n",
    "• Use ReLU activation in generator for all layers except for the output, which uses Tanh.\n",
    "• Use LeakyReLU activation in the discriminator for all layers.\n",
    "``` -->\n",
    "\n",
    "\n",
    "*   Use convolutions without any pooling layers\n",
    "*   Use batchnorm in both the generator and the discriminator\n",
    "*   Don't use fully connected hidden layers\n",
    "*   Use ReLU activation in the generator for all layers except for the output, which uses a Tanh activation.\n",
    "*   Use LeakyReLU activation in the discriminator for all layers except for the output, which does not use an activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9742e887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sankalp\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:159: UserWarning: pylab import has clobbered these variables: ['real', 'Generator']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import make_grid\n",
    "%pylab inline\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba7ddd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disciminator\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_ch=1, hidden_dim=16):\n",
    "        super().__init__()\n",
    "        self.disc = nn.Sequential(self.block(img_ch, hidden_dim),\n",
    "                                 self.block(hidden_dim, hidden_dim*2),\n",
    "                                 nn.Conv2d(hidden_dim*2, 1, 4, 2))\n",
    "        \n",
    "    def block(self, in_channel, op_channel, kernel_size=4, stride=2):\n",
    "        return nn.Sequential(nn.Conv2d(in_channel, op_channel, kernel_size, stride),\n",
    "                            nn.BatchNorm2d(op_channel),\n",
    "                            nn.LeakyReLU(0.2))\n",
    "    \n",
    "    def forward(self, x):return self.disc(x)\n",
    "    \n",
    "# GENERAtor\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_ch=1, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.gen = nn.Sequential(self.block(z_dim, hidden_dim*4),\n",
    "                                self.block(hidden_dim*4, hidden_dim*2),\n",
    "                                self.block(hidden_dim*2, hidden_dim),\n",
    "                                nn.ConvTranspose2d(hidden_dim, img_ch, 3, 2),\n",
    "                                nn.Tanh())\n",
    "        \n",
    "    def block(self, in_channel, op_channel, kernel_size=3, stride=2):\n",
    "        return nn.Sequential(nn.ConvTranspose2d(in_channel, op_channel, kernel_size, stride),\n",
    "                            nn.BatchNorm2d(op_channel),\n",
    "                            nn.ReLU())\n",
    "    \n",
    "    def forward(self, x):return self.gen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce8b0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2cdb6b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 64\n",
    "batch_size = 128\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "lr = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "455e2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "dataset = datasets.MNIST(r\"C:\\Users\\sankalp\\Desktop\\Computer Vision\\GAN\\Data\", download=True, transform=transform)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eec6f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator().to(device)\n",
    "gen = Generator(z_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1635279",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_disc = optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optim_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76023165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEIGHTS\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "# Applying WEIGHTS\n",
    "\n",
    "disc = disc.apply(weights_init)\n",
    "gen = gen.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e035e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "test_noise = torch.randn(batch_size, z_dim, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f161538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_fake = SummaryWriter(f'logs_dcgan/fake')\n",
    "summary_real = SummaryWriter(f'logs_dcgan/real')\n",
    "\n",
    "test_noise = torch.randn(batch_size, z_dim, 1, 1).to(device)\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b95a0e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12840), started 0:06:34 ago. (Use '!kill 12840' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5856a3ea5a5a080f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5856a3ea5a5a080f\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs_dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f356755c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-4008bb704328>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mgen_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mgen_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0moptim_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real, _) in enumerate(dataloader):\n",
    "        real = real.to(device)\n",
    "        noise = torch.randn(batch_size, z_dim, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real)\n",
    "        disc_fake = disc(fake)\n",
    "        disc_fake_loss = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        disc_real_loss = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_loss = (disc_fake_loss + disc_real_loss)/2\n",
    "        disc.zero_grad()\n",
    "        disc_loss.backward(retain_graph=True)\n",
    "        optim_disc.step()\n",
    "        \n",
    "        output = disc(fake)\n",
    "        gen_loss = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        optim_gen.step()\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            with torch.no_grad():\n",
    "                fake = gen(test_noise)\n",
    "                summary_fake.add_image('Fake', make_grid(fake, normalize=True), global_step=step)\n",
    "                summary_real.add_image('Real', make_grid(real, normalize=True), global_step=step)\n",
    "            step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea1319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
